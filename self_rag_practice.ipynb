{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=100, chunk_overlap=50\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_blog_posts\",\n",
    "    \"Search and return information about Lilian Weng blog posts on LLM agents, prompt engineering, and adversarial attacks on LLMs.\",\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look into the retriever grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "system = \"\"\"You are a grader checking if a document is relevant to a userâ€™s question.The check has to be done very strictly..  \n",
    "If the document has words or meanings related to the question, mark it as relevant.  \n",
    "Give a simple 'yes' or 'no' answer to show if the document is relevant or not.\"\"\"\n",
    "    \n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "question = \"agent memory\"\n",
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_txt = docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's look into the data generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
      "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LLM-powered agents utilize both short-term and long-term memory.  Short-term memory is handled through in-context learning, while long-term memory often involves an external vector store for information retrieval.  This allows agents to retain and recall information over extended periods.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-8db42adb-4bef-4705-8ff3-f556c57800f7-0', usage_metadata={'input_tokens': 2094, 'output_tokens': 58, 'total_tokens': 2152, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallucination Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data model\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "system = \"\"\"You are a grader checking if an LLM generation is grounded in or supported by a set of retrieved facts.  \n",
    "Give a simple 'yes' or 'no' answer. 'Yes' means the generation is grounded in or supported by a set of retrieved the facts.\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeHallucinations(binary_score='yes')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucinations_grader = hallucination_prompt | structured_llm_grader\n",
    "hallucinations_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeAnswer(binary_score='yes')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Answer Grader\n",
    "# Data model\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n \n",
    "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "answer_grader = answer_prompt | structured_llm_grader\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Re-writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the different types of agent memory and how do they function?'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for vector store retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "     \n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_question = question_rewriter.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here the Langgraph workflow will start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state:AgentState):\n",
    "    print(\"----RETRIEVE----\")\n",
    "    question=state['question']\n",
    "    documents=retriever.get_relevant_documents(question)\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state:AgentState):\n",
    "    print(\"----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\")\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    \n",
    "    filtered_docs = []\n",
    "    for doc in documents:\n",
    "        score=retrieval_grader.invoke({\"question\":question, \"document\":doc})\n",
    "        grade=score.binary_score\n",
    "        \n",
    "        if grade=='yes':\n",
    "            print(\"----GRADE: DOCUMENT RELEVANT----\")\n",
    "            filtered_docs.append(doc)\n",
    "        else:\n",
    "            print(\"----GRADE: DOCUMENT NOT RELEVANT----\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state:AgentState):\n",
    "    print(\"----ACCESS GRADED DOCUMENTS----\")\n",
    "    state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "    \n",
    "    if not filtered_documents:\n",
    "        print(\"----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\")\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        print(\"----DECISION: GENERATE----\")\n",
    "        return \"generate\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state:AgentState):\n",
    "    print(\"----GENERATE----\")\n",
    "    question=state[\"question\"]\n",
    "    documents=state[\"documents\"]\n",
    "    \n",
    "    generation = rag_chain.invoke({\"context\": documents,\"question\":question})\n",
    "    return {\"documents\":documents,\"question\":question,\"generation\":generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_query(state:AgentState):\n",
    "    question=state[\"question\"]\n",
    "    documents=state[\"documents\"]\n",
    "    \n",
    "    better_question = question_rewriter.invoke({\"question\":question})\n",
    "    return {\"documents\":documents,\"question\":better_question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "def grade_generation_vs_documents_and_question(state:AgentState):\n",
    "    print(\"---CHECK HELLUCINATIONS---\")\n",
    "    question= state['question']\n",
    "    documents = state['documents']\n",
    "    generation = state[\"generation\"]\n",
    "    \n",
    "    score = hallucinations_grader.invoke({\"documents\":documents,\"generation\":generation})\n",
    "    \n",
    "    grade = score.binary_score\n",
    "    \n",
    "    #Check hallucinations\n",
    "    if grade=='yes':\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        \n",
    "        print(\"---GRADE GENERATION vs QUESTION ---\")\n",
    "        \n",
    "        score = answer_grader.invoke({\"question\":question,\"generation\":generation})\n",
    "        \n",
    "        grade = score.binary_score\n",
    "        \n",
    "        if grade=='yes':\n",
    "            print(\"---DECISION: GENERATION ADDRESS THE QUESTION ---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17fe2a6fdf0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Docs_Vector_Retrieve\", retrieve)\n",
    "workflow.add_node(\"Grading_Generated_Documents\", grade_documents) \n",
    "workflow.add_node(\"Content_Generator\", generate)\n",
    "workflow.add_node(\"Transform_User_Query\", transform_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17fe2a6fdf0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(START, \"Docs_Vector_Retrieve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17fe2a6fdf0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(\"Docs_Vector_Retrieve\",\"Grading_Generated_Documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17fe2a6fdf0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_conditional_edges(\"Grading_Generated_Documents\",\n",
    "                            decide_to_generate,\n",
    "                            {\n",
    "                            \"generate\": \"Content_Generator\",\n",
    "                            \"transform_query\": \"Transform_User_Query\"\n",
    "                            }\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17fe2a6fdf0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_conditional_edges(\"Content_Generator\",\n",
    "                            grade_generation_vs_documents_and_question,\n",
    "                            {\n",
    "                            \"useful\": END,\n",
    "                            \"not useful\": \"Transform_User_Query\",\n",
    "                            }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17fe2a6fdf0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(\"Transform_User_Query\", \"Docs_Vector_Retrieve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display # type: ignore\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"Explain how the different types of agent memory work?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION ---\n",
      "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Explain how the different types of agent memory work?',\n",
       " 'generation': AIMessage(content='Short-term memory uses in-context learning,  while long-term memory retains information over extended periods using external storage like a vector store for fast retrieval.  This allows the agent to learn from past experiences and access a broader range of information.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-bdd7c9d5-9c9c-499d-84a4-924aa4fd78e6-0', usage_metadata={'input_tokens': 2078, 'output_tokens': 51, 'total_tokens': 2129, 'input_token_details': {'cache_read': 0}}),\n",
       " 'documents': [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use'),\n",
       "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use'),\n",
       "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use'),\n",
       "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use')]}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"who is a prompt engineering?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION ---\n",
      "---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION ---\n",
      "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the core principles and essential skills for effective prompt engineering?',\n",
       " 'generation': AIMessage(content=\"Core principles of effective prompt engineering include alignment and model steerability, aiming to guide the Large Language Model (LLM) behavior without modifying its weights.  Essential skills involve experimentation and iterative refinement, as the effectiveness of methods varies across models.  It's an empirical process requiring heuristics.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-d435bfe3-9853-4ef7-91ba-bb621be9ca25-0', usage_metadata={'input_tokens': 1033, 'output_tokens': 59, 'total_tokens': 1092, 'input_token_details': {'cache_read': 0}}),\n",
       " 'documents': [Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.'),\n",
       "  Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.'),\n",
       "  Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.'),\n",
       "  Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.')]}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"what is role of data structure while creating agentic pattern?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION ---\n",
      "---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----GRADE: DOCUMENT NOT RELEVANT----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Resource has been exhausted (e.g. check quota).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1936\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1934\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1935\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1936\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   1937\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1938\u001b[0m     config,\n\u001b[0;32m   1939\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   1940\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   1941\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   1942\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   1943\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1947\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1656\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1650\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1652\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1656\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1657\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1658\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1659\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1660\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1661\u001b[0m         ):\n\u001b[0;32m   1662\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1663\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1664\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langgraph\\pregel\\runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langgraph\\utils\\runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m )\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langgraph\\utils\\runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[86], line 8\u001b[0m, in \u001b[0;36mgrade_documents\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      6\u001b[0m filtered_docs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[1;32m----> 8\u001b[0m     score\u001b[38;5;241m=\u001b[39m\u001b[43mretrieval_grader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocument\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     grade\u001b[38;5;241m=\u001b[39mscore\u001b[38;5;241m.\u001b[39mbinary_score\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m grade\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3023\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3024\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5354\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5350\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5351\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5355\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5356\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5357\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5358\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    285\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    287\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    288\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    289\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    290\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    291\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    292\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    293\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    294\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    295\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    634\u001b[0m                 m,\n\u001b[0;32m    635\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    636\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    637\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    638\u001b[0m             )\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    852\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    853\u001b[0m         )\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:949\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[1;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m    924\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    925\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    937\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m    938\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[0;32m    939\u001b[0m         messages,\n\u001b[0;32m    940\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    947\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[0;32m    948\u001b[0m     )\n\u001b[1;32m--> 949\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m _chat_with_retry(\n\u001b[0;32m    950\u001b[0m         request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[0;32m    951\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    952\u001b[0m         generation_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mgenerate_content,\n\u001b[0;32m    953\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata,\n\u001b[0;32m    954\u001b[0m     )\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:196\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[1;34m(generation_method, **kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chat_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\tenacity\\__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\tenacity\\__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\tenacity\\__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\tenacity\\__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\tenacity\\__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\tenacity\\__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:194\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:178\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mFailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\youtubelive\\venv\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota)."
     ]
    }
   ],
   "source": [
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
